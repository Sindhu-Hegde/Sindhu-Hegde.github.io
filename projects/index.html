<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Sindhu B. Hegde | Projects</title>
    <meta name="author" content="Sindhu B. Hegde" />
    <meta name="description" content="A list of exciting projects that I have been a part of! Will be updated as and when possible." />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/icon.jpg"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://sindhu-hegde.github.io/projects/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://Sindhu-Hegde.github.io/"><span class="font-weight-bold">Sindhu</span> B.  Hegde</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/assets/pdf/Resume_SindhuHegde.pdf">CV</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/projects/">Projects<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Projects</h1>
    <p class="post-description">A list of exciting projects that I have been a part of! Will be updated as and when possible.</p>
  </header>

  <article>
    <h3 style="text-align:right; color:#D3D3D3;">publications</h3>
<hr>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

  <tr>
    <td style="width:25%;vertical-align:middle">
      <div class="one">
        <img src="/assets/img/acm_videosr_banner.png" width="300" height="140">
      </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://dl.acm.org/doi/10.1145/3503161.3548080" target="_blank" rel="noopener noreferrer">
        <papertitle><b>Extreme-scale Talking-Face Video Upsampling with Audio-Visual Priors</b></papertitle>
      </a>
      <br>
      <strong>Sindhu B Hegde*</strong>,
      Rudrabha Mukhopadhyay*,  
      Vinay P Namboodiri,
      C. V. Jawahar
      <br>
      <em>ACM-MM</em>, 2022 <span style="color:red"></span>
      <br>
      <a href="https://arxiv.org/pdf/2208.08118.pdf" target="_blank" rel="noopener noreferrer">arXiv</a> /
      <a href="https://github.com/Sindhu-Hegde/video-super-resolver" target="_blank" rel="noopener noreferrer">code</a> /
      <a href="http://cvit.iiit.ac.in/research/projects/cvit-projects/talking-face-video-upsampling" target="_blank" rel="noopener noreferrer">project page</a> 
      <p></p>
      <p>Super-resolve extremely low-resolution videos (eg., 8x8 pixels) to obtain realistic, high-resolution outputs (256x256 pixels). Upsampled the videos at a scale-factor of 32x for the first time!.</p>
    </td>
  </tr>

  <tr>
    <td style="width:25%;vertical-align:middle">
      <div class="one">
        <img src="/assets/img/acm_l2s_banner.png" width="320" height="120">
      </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://dl.acm.org/doi/10.1145/3503161.3548081" target="_blank" rel="noopener noreferrer">
        <papertitle><b>Lip-to-Speech Synthesis for Arbitrary Speakers in the Wild</b></papertitle>
      </a>
      <br>
      <strong>Sindhu B Hegde*</strong>,
      K R Prajwal*,
      Rudrabha Mukhopadhyay*,  
      Vinay P Namboodiri,
      C. V. Jawahar
      <br>
      <em>ACM-MM</em>, 2022 <span style="color:red"></span>
      <br>
      <a href="https://arxiv.org/pdf/2209.00642.pdf" target="_blank" rel="noopener noreferrer">arXiv</a> /
      <a href="https://github.com/Sindhu-Hegde/lip2speech" target="_blank" rel="noopener noreferrer">code</a> /
      <a href="http://cvit.iiit.ac.in/research/projects/cvit-projects/lip-to-speech-synthesis" target="_blank" rel="noopener noreferrer">project page</a> 
      <p></p>
      <p>Generates speech for silent talking face videos for any speaker in-the-wild! One of the first models to work for arbitrary speakers, with no explicit costraints in the domain or vocabulary.</p>
    </td>
  </tr>

  <tr>
    <td style="width:25%;vertical-align:middle">
      <div class="one">
        <img src="/assets/img/bmvc21_banner.png" width="320" height="100">
      </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://www.bmvc2021-virtualconference.com/assets/papers/0930.pdf" target="_blank" rel="noopener noreferrer">
        <papertitle><b>Audio-Visual Speech Super-Resolution</b></papertitle>
      </a>
      <br>
      Rudrabha Mukhopadhyay*, 
      <strong>Sindhu B Hegde*</strong>, 
      Vinay P Namboodiri,
      C. V. Jawahar
      <br>
      <em>BMVC</em>, 2021 <span style="color:red"><b>(Oral Presentation)</b></span>
      <br>
      <a href="https://www.bmvc2021-virtualconference.com/assets/papers/0930.pdf" target="_blank" rel="noopener noreferrer">pdf</a> /
      <a href="https://www.bmvc2021-virtualconference.com/conference/papers/paper_0930.html" target="_blank" rel="noopener noreferrer">presentation</a> /
      <a href="http://cvit.iiit.ac.in/research/projects/cvit-projects/audio-visual-speech-super-resolution" target="_blank" rel="noopener noreferrer">project page</a> 
      <p></p>
      <p>An audio-visual model to super-reolve very low-resolution speech signals (e.g., 1kHz) &amp; generate high-quality speech (16kHz). Works even if the real-visual stream is unavailable/corrupted using the proposed pseudo-visual approach!</p>
    </td>
  </tr>

  <tr>
    <td style="width:25%;vertical-align:middle">
      <div class="one">
        <img src="/assets/img/wacv21_banner.gif" width="320" height="200" style="vertical-align:middle">
      </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Hegde_Visual_Speech_Enhancement_Without_a_Real_Visual_Stream_WACV_2021_paper.pdf" target="_blank" rel="noopener noreferrer">
        <papertitle><b>Visual Speech Enhancement Without A Real Visual Stream</b></papertitle>
      </a>
      <br>
      <strong>Sindhu B Hegde*</strong>, 
      K R Prajwal*,
      Rudrabha Mukhopadhyay*, 
      Vinay P Namboodiri,
      C. V. Jawahar
      <br>
      <em>WACV</em>, 2021
      <br>
      <a href="https://arxiv.org/abs/2012.10852" target="_blank" rel="noopener noreferrer">arXiv</a> /
      <a href="https://www.youtube.com/watch?v=y_oP9t7WEn4" target="_blank" rel="noopener noreferrer">demo video</a> /
      <a href="https://www.youtube.com/watch?v=Dqx6d-XdQCI" target="_blank" rel="noopener noreferrer">presentation</a> /
      <a href="https://github.com/Sindhu-Hegde/pseudo-visual-speech-denoising" target="_blank" rel="noopener noreferrer">code</a> /
      <a href="http://cvit.iiit.ac.in/research/projects/cvit-projects/visual-speech-enhancement-without-a-real-visual-stream" target="_blank" rel="noopener noreferrer">project page</a> 
      <p></p>
      <p>A new paradigm for speech enhancement that works effectively in unconstrained, high-noise, real-world environments. A hybrid approach to hallucinate the visual stream using only the noisy speech as input.</p>
    </td>
  </tr>

  <tr>
    <td style="width:25%;vertical-align:middle">
      <div class="one">
        <img src="/assets/img/interspeech21_banner.png" width="318" height="180" style="vertical-align:middle">
      </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://arxiv.org/pdf/2106.12790.pdf" target="_blank" rel="noopener noreferrer">
        <papertitle><b>Towards Automatic Speech to Sign Language Generation</b></papertitle>
      </a>
      <br>
      Parul Kapoor,
      Rudrabha Mukhopadhyay, 
      <strong>Sindhu B Hegde</strong>, 
      Vinay P Namboodiri,
      C. V. Jawahar
      <br>
      <em>INTERSPEECH</em>, 2021
      <br>
      <a href="https://arxiv.org/abs/2012.10852" target="_blank" rel="noopener noreferrer">arXiv</a> /
      <a href="http://cvit.iiit.ac.in/images/Projects/speech2sl/INTERSPEECH_long_video.mp4" target="_blank" rel="noopener noreferrer">demo video</a> /
      <a href="https://github.com/kapoorparul/Towards-Automatic-Speech-to-SL" target="_blank" rel="noopener noreferrer">code</a> /
      <a href="http://cvit.iiit.ac.in/research/projects/cvit-projects/towards-speech-to-sign-language-generation" target="_blank" rel="noopener noreferrer">project page</a> 
      <p></p>
      <p>Generated continuous sign-language videos solely from speech segments for the first time. Also curated and released the first Indian Sign Language (ISL) dataset comprising speech annotations, transcripts &amp; sign-language videos.</p>
    </td>
  </tr>

  <tr>
    <td style="width:25%;vertical-align:middle">
      <div class="one">
        <img src="/assets/img/icprdemo_banner.png" width="318" height="160" style="vertical-align:middle">
      </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://arxiv.org/pdf/2106.12790.pdf" target="_blank" rel="noopener noreferrer">
        <papertitle><b>The Interplay of Speech and Lip Movements </b></papertitle>
      </a>
      <br>
      Rudrabha Mukhopadhyay*,
      K R Prajwal*, 
      <strong>Sindhu B Hegde*</strong>, 
      Vinay P Namboodiri,
      C. V. Jawahar
      <br>
      <em>ICPR Demonstrations</em>, 2020
      <br>
      <a href="https://www.youtube.com/watch?v=ydj4Ach3d8I" target="_blank" rel="noopener noreferrer">demo video</a> /
      <a href="https://www.micc.unifi.it/icpr2020/wp-content/uploads/demos/s3.2-paper.pdf" target="_blank" rel="noopener noreferrer">writeup</a>  
      <p></p>
      <p>Extensively explore the correlation between vision and speech modalities, specifically the speech and lip movements.</p>
    </td>
  </tr>

</tbody></table>

<h3 style="text-align:right; color:#D3D3D3;">implementations</h3>
<hr>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

  <tr>
    <td style="width:25%;vertical-align:middle">
      <div class="one">
        <img src="/assets/img/spsep_banner.png" width="320" height="140">
      </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://github.com/Sindhu-Hegde/speaker-separation" target="_blank" rel="noopener noreferrer">
        <papertitle><b>Audio-Visual Speaker Separation</b></papertitle>
      </a>
      <br>
      <a href="https://github.com/Sindhu-Hegde/speaker-separation" target="_blank" rel="noopener noreferrer">code</a> /
      <a href="https://colab.research.google.com/github/Sindhu-Hegde/speaker-separation/blob/main/speaker_separation_inference.ipynb" target="_blank" rel="noopener noreferrer">colab</a> /
      <a href="https://docs.google.com/presentation/d/1dqzbBOLL7-bHdJ0rWB4Mo-tEaHn_9p_qkw8yIbl73jA/edit?usp=sharing" target="_blank" rel="noopener noreferrer">presentation</a> 
      <p></p>
      <p>Separate the two speakers talking simultaneously in a cocktail-party like situation. An audio-visual model to enhance &amp; isolate the speech of the target speaker.</p>
      <b>Papers referred:</b><br>
      (1) <a href="https://arxiv.org/pdf/1804.04121.pdf" target="_blank" rel="noopener noreferrer">The Conversation: Deep Audio-Visual Speech Enhancement</a><br>
      (2) <a href="https://dl.acm.org/doi/pdf/10.1145/3197517.3201357" target="_blank" rel="noopener noreferrer">Looking to Listen at the Cocktail Party: A Speaker-Independent Audio-Visual Model for Speech Separation</a>
    </td>
  </tr>

  <tr>
    <td style="width:25%;vertical-align:middle">
      <div class="one">
        <img src="/assets/img/yst_banner.png" width="320" height="60">
      </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://github.com/Sindhu-Hegde/you_said_that" target="_blank" rel="noopener noreferrer">
        <papertitle><b>Speech-driven Lip Synthesis</b></papertitle>
      </a>
      <br>
      <a href="https://github.com/Sindhu-Hegde/you_said_that" target="_blank" rel="noopener noreferrer">code</a>
      <p></p>
      <p>Generate a talking-face video from the still image of the target identity &amp; the corresponding speech segment. Works for unseen faces &amp; audios!</p>
      <b>Papers referred:</b><br>
      (1) <a href="https://www.robots.ox.ac.uk/~vgg/publications/2017/Chung17b/chung17b.pdf" target="_blank" rel="noopener noreferrer">You said that?</a><br>
      (2) <a href="https://arxiv.org/pdf/2003.00418.pdf" target="_blank" rel="noopener noreferrer">Towards Automatic Face-to-Face Translation</a>
    </td>
  </tr>

</tbody></table>

  </article>

</div>
    </div>

    <!-- Footer -->


<footer class="fixed-bottom">
  <div class="container mt-0">
    Â© Copyright 2023 Sindhu B. Hegde.
    <c> <br> <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme on <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </c>

    
    Last updated: October 04, 2023.
    
  </div>
</footer>



    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

